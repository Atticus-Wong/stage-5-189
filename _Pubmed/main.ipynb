{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95aa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Dataset_Loader_Node_Classification import Dataset_Loader\n",
    "from gcn.models import GCN\n",
    "from gcn.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc6af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pubmed dataset...\n",
      "Data Loaded:\n",
      "  Features shape: torch.Size([19717, 500])\n",
      "  Adjacency matrix shape: torch.Size([19717, 19717])\n",
      "  Labels shape: torch.Size([19717])\n",
      "  Number of training samples: 60\n",
      "  Number of validation samples: 300\n",
      "  Number of testing samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Initialize Dataset_Loader for Pubmed\n",
    "# The dName 'pubmed' should match the folder name in 'stage_5_data'\n",
    "# and the dataset_name attribute in Dataset_Loader for specific train/test/val splits.\n",
    "data_loader = Dataset_Loader(dName='pubmed', dDescription='Pubmed citation network')\n",
    "data_loader.dataset_name = 'pubmed' # Set dataset_name for train/val/test splits\n",
    "data_loader.dataset_source_folder_path = '../stage_5_data/pubmed/'  # Path to the dataset folder\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the correct data path if needed (adjust the path as necessary)\n",
    "data_loader.data_path = '../stage_5_data/pubmed/'  # or the correct relative/absolute path to your data\n",
    "\n",
    "# Check if the data path exists\n",
    "if not os.path.exists(data_loader.data_path):\n",
    "\traise FileNotFoundError(f\"Data path does not exist: {data_loader.data_path}\")\n",
    "\n",
    "loaded_data = data_loader.load()\n",
    "\n",
    "graph_data = loaded_data['graph']\n",
    "train_test_val_indices = loaded_data['train_test_val']\n",
    "\n",
    "adj = graph_data['utility']['A']\n",
    "features = graph_data['X']\n",
    "labels = graph_data['y']\n",
    "\n",
    "idx_train = train_test_val_indices['idx_train']\n",
    "idx_val = train_test_val_indices['idx_val']\n",
    "idx_test = train_test_val_indices['idx_test']\n",
    "\n",
    "print(\"Data Loaded:\")\n",
    "print(f\"  Features shape: {features.shape}\")\n",
    "print(f\"  Adjacency matrix shape: {adj.shape}\")\n",
    "print(f\"  Labels shape: {labels.shape}\")\n",
    "print(f\"  Number of training samples: {len(idx_train)}\")\n",
    "print(f\"  Number of validation samples: {len(idx_val)}\")\n",
    "print(f\"  Number of testing samples: {len(idx_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e090da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized:\n",
      "GCN(\n",
      "  (gc1): GraphConvolution (500 -> 16)\n",
      "  (gc2): GraphConvolution (16 -> 3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- 2. Model, Optimizer, and Hyperparameters ---\n",
    "# Hyperparameters (similar to _Pubmed/train.py)\n",
    "n_epochs = 200\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "hidden_units = 16\n",
    "dropout_rate = 0.5\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Model initialization\n",
    "n_features = features.shape[1]\n",
    "n_classes = labels.max().item() + 1\n",
    "\n",
    "model = GCN(nfeat=n_features,\n",
    "            nhid=hidden_units,\n",
    "            nclass=n_classes,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "if cuda_available:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "\n",
    "print(\"Model Initialized:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de260ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch: 0001 loss_train: 1.1107 acc_train: 0.3500 loss_val: 1.1145 acc_val: 0.3633 time: 0.0372s\n",
      "Epoch: 0002 loss_train: 1.0944 acc_train: 0.4167 loss_val: 1.1083 acc_val: 0.3367 time: 0.0226s\n",
      "Epoch: 0003 loss_train: 1.0774 acc_train: 0.5000 loss_val: 1.1015 acc_val: 0.3400 time: 0.0198s\n",
      "Epoch: 0004 loss_train: 1.0749 acc_train: 0.4500 loss_val: 1.0945 acc_val: 0.3467 time: 0.0204s\n",
      "Epoch: 0005 loss_train: 1.0634 acc_train: 0.4833 loss_val: 1.0861 acc_val: 0.3733 time: 0.0203s\n",
      "Epoch: 0006 loss_train: 1.0477 acc_train: 0.5167 loss_val: 1.0759 acc_val: 0.4300 time: 0.0199s\n",
      "Epoch: 0007 loss_train: 1.0301 acc_train: 0.5667 loss_val: 1.0637 acc_val: 0.4867 time: 0.0203s\n",
      "Epoch: 0008 loss_train: 1.0252 acc_train: 0.5667 loss_val: 1.0507 acc_val: 0.5333 time: 0.0198s\n",
      "Epoch: 0009 loss_train: 0.9982 acc_train: 0.6000 loss_val: 1.0372 acc_val: 0.5533 time: 0.0227s\n",
      "Epoch: 0010 loss_train: 0.9923 acc_train: 0.6333 loss_val: 1.0238 acc_val: 0.5600 time: 0.0218s\n",
      "Epoch: 0011 loss_train: 0.9939 acc_train: 0.6333 loss_val: 1.0113 acc_val: 0.5667 time: 0.0246s\n",
      "Epoch: 0012 loss_train: 0.9581 acc_train: 0.6500 loss_val: 0.9999 acc_val: 0.6000 time: 0.0216s\n",
      "Epoch: 0013 loss_train: 0.9492 acc_train: 0.7667 loss_val: 0.9885 acc_val: 0.6133 time: 0.0218s\n",
      "Epoch: 0014 loss_train: 0.9452 acc_train: 0.7333 loss_val: 0.9776 acc_val: 0.6567 time: 0.0204s\n",
      "Epoch: 0015 loss_train: 0.9158 acc_train: 0.7333 loss_val: 0.9673 acc_val: 0.6700 time: 0.0226s\n",
      "Epoch: 0016 loss_train: 0.9011 acc_train: 0.7833 loss_val: 0.9576 acc_val: 0.7000 time: 0.0200s\n",
      "Epoch: 0017 loss_train: 0.8962 acc_train: 0.7500 loss_val: 0.9481 acc_val: 0.7267 time: 0.0208s\n",
      "Epoch: 0018 loss_train: 0.8835 acc_train: 0.7500 loss_val: 0.9389 acc_val: 0.7367 time: 0.0190s\n",
      "Epoch: 0019 loss_train: 0.8844 acc_train: 0.7333 loss_val: 0.9293 acc_val: 0.7400 time: 0.0215s\n",
      "Epoch: 0020 loss_train: 0.8594 acc_train: 0.8000 loss_val: 0.9195 acc_val: 0.7400 time: 0.0219s\n",
      "Epoch: 0021 loss_train: 0.8397 acc_train: 0.8167 loss_val: 0.9098 acc_val: 0.7433 time: 0.0200s\n",
      "Epoch: 0022 loss_train: 0.8312 acc_train: 0.8000 loss_val: 0.9000 acc_val: 0.7400 time: 0.0200s\n",
      "Epoch: 0023 loss_train: 0.8344 acc_train: 0.7500 loss_val: 0.8903 acc_val: 0.7333 time: 0.0210s\n",
      "Epoch: 0024 loss_train: 0.7950 acc_train: 0.8000 loss_val: 0.8809 acc_val: 0.7333 time: 0.0217s\n",
      "Epoch: 0025 loss_train: 0.7958 acc_train: 0.8500 loss_val: 0.8712 acc_val: 0.7400 time: 0.0204s\n",
      "Epoch: 0026 loss_train: 0.7775 acc_train: 0.7667 loss_val: 0.8621 acc_val: 0.7467 time: 0.0196s\n",
      "Epoch: 0027 loss_train: 0.7493 acc_train: 0.8667 loss_val: 0.8525 acc_val: 0.7467 time: 0.0201s\n",
      "Epoch: 0028 loss_train: 0.7430 acc_train: 0.8333 loss_val: 0.8428 acc_val: 0.7500 time: 0.0198s\n",
      "Epoch: 0029 loss_train: 0.7038 acc_train: 0.8833 loss_val: 0.8332 acc_val: 0.7533 time: 0.0215s\n",
      "Epoch: 0030 loss_train: 0.6952 acc_train: 0.9333 loss_val: 0.8235 acc_val: 0.7567 time: 0.0226s\n",
      "Epoch: 0031 loss_train: 0.6835 acc_train: 0.8667 loss_val: 0.8141 acc_val: 0.7567 time: 0.0201s\n",
      "Epoch: 0032 loss_train: 0.6767 acc_train: 0.8667 loss_val: 0.8053 acc_val: 0.7600 time: 0.0200s\n",
      "Epoch: 0033 loss_train: 0.6672 acc_train: 0.8833 loss_val: 0.7966 acc_val: 0.7600 time: 0.0209s\n",
      "Epoch: 0034 loss_train: 0.6620 acc_train: 0.8833 loss_val: 0.7884 acc_val: 0.7633 time: 0.0201s\n",
      "Epoch: 0035 loss_train: 0.6569 acc_train: 0.8500 loss_val: 0.7806 acc_val: 0.7667 time: 0.0192s\n",
      "Epoch: 0036 loss_train: 0.6169 acc_train: 0.8667 loss_val: 0.7733 acc_val: 0.7633 time: 0.0203s\n",
      "Epoch: 0037 loss_train: 0.6461 acc_train: 0.8333 loss_val: 0.7657 acc_val: 0.7667 time: 0.0202s\n",
      "Epoch: 0038 loss_train: 0.6003 acc_train: 0.8333 loss_val: 0.7583 acc_val: 0.7633 time: 0.0202s\n",
      "Epoch: 0039 loss_train: 0.5977 acc_train: 0.8333 loss_val: 0.7516 acc_val: 0.7600 time: 0.0203s\n",
      "Epoch: 0040 loss_train: 0.5824 acc_train: 0.8500 loss_val: 0.7449 acc_val: 0.7567 time: 0.0232s\n",
      "Epoch: 0041 loss_train: 0.5856 acc_train: 0.9000 loss_val: 0.7386 acc_val: 0.7567 time: 0.0209s\n",
      "Epoch: 0042 loss_train: 0.5535 acc_train: 0.8667 loss_val: 0.7319 acc_val: 0.7567 time: 0.0209s\n",
      "Epoch: 0043 loss_train: 0.5160 acc_train: 0.9167 loss_val: 0.7253 acc_val: 0.7600 time: 0.0200s\n",
      "Epoch: 0044 loss_train: 0.5362 acc_train: 0.9000 loss_val: 0.7187 acc_val: 0.7600 time: 0.0210s\n",
      "Epoch: 0045 loss_train: 0.5211 acc_train: 0.8833 loss_val: 0.7128 acc_val: 0.7533 time: 0.0202s\n",
      "Epoch: 0046 loss_train: 0.5114 acc_train: 0.9333 loss_val: 0.7073 acc_val: 0.7600 time: 0.0199s\n",
      "Epoch: 0047 loss_train: 0.5012 acc_train: 0.9167 loss_val: 0.7026 acc_val: 0.7667 time: 0.0193s\n",
      "Epoch: 0048 loss_train: 0.5089 acc_train: 0.8667 loss_val: 0.6971 acc_val: 0.7667 time: 0.0199s\n",
      "Epoch: 0049 loss_train: 0.4818 acc_train: 0.9000 loss_val: 0.6914 acc_val: 0.7700 time: 0.0216s\n",
      "Epoch: 0050 loss_train: 0.5233 acc_train: 0.8833 loss_val: 0.6847 acc_val: 0.7700 time: 0.0218s\n",
      "Epoch: 0051 loss_train: 0.4541 acc_train: 0.9667 loss_val: 0.6774 acc_val: 0.7800 time: 0.0195s\n",
      "Epoch: 0052 loss_train: 0.4137 acc_train: 0.9667 loss_val: 0.6705 acc_val: 0.7767 time: 0.0197s\n",
      "Epoch: 0053 loss_train: 0.4409 acc_train: 0.9000 loss_val: 0.6640 acc_val: 0.7767 time: 0.0202s\n",
      "Epoch: 0054 loss_train: 0.4156 acc_train: 0.9500 loss_val: 0.6581 acc_val: 0.7833 time: 0.0196s\n",
      "Epoch: 0055 loss_train: 0.4433 acc_train: 0.8667 loss_val: 0.6533 acc_val: 0.7833 time: 0.0207s\n",
      "Epoch: 0056 loss_train: 0.3565 acc_train: 0.9833 loss_val: 0.6488 acc_val: 0.7833 time: 0.0208s\n",
      "Epoch: 0057 loss_train: 0.3638 acc_train: 0.9333 loss_val: 0.6448 acc_val: 0.7833 time: 0.0194s\n",
      "Epoch: 0058 loss_train: 0.3506 acc_train: 0.9333 loss_val: 0.6412 acc_val: 0.7833 time: 0.0203s\n",
      "Epoch: 0059 loss_train: 0.3287 acc_train: 0.9333 loss_val: 0.6379 acc_val: 0.7767 time: 0.0247s\n",
      "Epoch: 0060 loss_train: 0.3691 acc_train: 0.9167 loss_val: 0.6350 acc_val: 0.7767 time: 0.0238s\n",
      "Epoch: 0061 loss_train: 0.3359 acc_train: 0.9500 loss_val: 0.6321 acc_val: 0.7700 time: 0.0210s\n",
      "Epoch: 0062 loss_train: 0.3888 acc_train: 0.9333 loss_val: 0.6291 acc_val: 0.7767 time: 0.0213s\n",
      "Epoch: 0063 loss_train: 0.3214 acc_train: 0.9500 loss_val: 0.6259 acc_val: 0.7767 time: 0.0242s\n",
      "Epoch: 0064 loss_train: 0.3473 acc_train: 0.9667 loss_val: 0.6218 acc_val: 0.7733 time: 0.0208s\n",
      "Epoch: 0065 loss_train: 0.3060 acc_train: 0.9833 loss_val: 0.6175 acc_val: 0.7767 time: 0.0207s\n",
      "Epoch: 0066 loss_train: 0.3179 acc_train: 0.9500 loss_val: 0.6140 acc_val: 0.7800 time: 0.0199s\n",
      "Epoch: 0067 loss_train: 0.3083 acc_train: 0.9500 loss_val: 0.6107 acc_val: 0.7767 time: 0.0221s\n",
      "Epoch: 0068 loss_train: 0.2799 acc_train: 0.9500 loss_val: 0.6078 acc_val: 0.7733 time: 0.0255s\n",
      "Epoch: 0069 loss_train: 0.2693 acc_train: 0.9833 loss_val: 0.6052 acc_val: 0.7733 time: 0.0222s\n",
      "Epoch: 0070 loss_train: 0.2698 acc_train: 1.0000 loss_val: 0.6030 acc_val: 0.7700 time: 0.0227s\n",
      "Epoch: 0071 loss_train: 0.3335 acc_train: 0.9500 loss_val: 0.6003 acc_val: 0.7700 time: 0.0210s\n",
      "Epoch: 0072 loss_train: 0.3065 acc_train: 0.9667 loss_val: 0.5964 acc_val: 0.7700 time: 0.0222s\n",
      "Epoch: 0073 loss_train: 0.2562 acc_train: 0.9500 loss_val: 0.5922 acc_val: 0.7733 time: 0.0203s\n",
      "Epoch: 0074 loss_train: 0.2793 acc_train: 0.9667 loss_val: 0.5893 acc_val: 0.7733 time: 0.0201s\n",
      "Epoch: 0075 loss_train: 0.2806 acc_train: 0.9500 loss_val: 0.5869 acc_val: 0.7733 time: 0.0192s\n",
      "Epoch: 0076 loss_train: 0.2475 acc_train: 0.9833 loss_val: 0.5850 acc_val: 0.7733 time: 0.0213s\n",
      "Epoch: 0077 loss_train: 0.2610 acc_train: 0.9500 loss_val: 0.5829 acc_val: 0.7733 time: 0.0205s\n",
      "Epoch: 0078 loss_train: 0.2180 acc_train: 1.0000 loss_val: 0.5816 acc_val: 0.7733 time: 0.0207s\n",
      "Epoch: 0079 loss_train: 0.2331 acc_train: 0.9667 loss_val: 0.5806 acc_val: 0.7733 time: 0.0199s\n",
      "Epoch: 0080 loss_train: 0.2419 acc_train: 0.9833 loss_val: 0.5809 acc_val: 0.7733 time: 0.0210s\n",
      "Epoch: 0081 loss_train: 0.2127 acc_train: 0.9667 loss_val: 0.5814 acc_val: 0.7733 time: 0.0203s\n",
      "Epoch: 0082 loss_train: 0.1988 acc_train: 1.0000 loss_val: 0.5820 acc_val: 0.7667 time: 0.0209s\n",
      "Epoch: 0083 loss_train: 0.2166 acc_train: 0.9833 loss_val: 0.5816 acc_val: 0.7733 time: 0.0206s\n",
      "Epoch: 0084 loss_train: 0.2164 acc_train: 0.9500 loss_val: 0.5810 acc_val: 0.7733 time: 0.0204s\n",
      "Epoch: 0085 loss_train: 0.1997 acc_train: 0.9833 loss_val: 0.5808 acc_val: 0.7733 time: 0.0200s\n",
      "Epoch: 0086 loss_train: 0.1984 acc_train: 1.0000 loss_val: 0.5806 acc_val: 0.7700 time: 0.0214s\n",
      "Epoch: 0087 loss_train: 0.2152 acc_train: 0.9833 loss_val: 0.5809 acc_val: 0.7700 time: 0.0207s\n",
      "Epoch: 0088 loss_train: 0.1863 acc_train: 0.9833 loss_val: 0.5813 acc_val: 0.7733 time: 0.0206s\n",
      "Epoch: 0089 loss_train: 0.1915 acc_train: 0.9500 loss_val: 0.5819 acc_val: 0.7767 time: 0.0233s\n",
      "Epoch: 0090 loss_train: 0.2168 acc_train: 0.9667 loss_val: 0.5805 acc_val: 0.7733 time: 0.0238s\n",
      "Epoch: 0091 loss_train: 0.1800 acc_train: 1.0000 loss_val: 0.5782 acc_val: 0.7700 time: 0.0236s\n",
      "Epoch: 0092 loss_train: 0.1924 acc_train: 1.0000 loss_val: 0.5764 acc_val: 0.7700 time: 0.0273s\n",
      "Epoch: 0093 loss_train: 0.1834 acc_train: 0.9667 loss_val: 0.5754 acc_val: 0.7733 time: 0.0202s\n",
      "Epoch: 0094 loss_train: 0.1784 acc_train: 1.0000 loss_val: 0.5741 acc_val: 0.7767 time: 0.0210s\n",
      "Epoch: 0095 loss_train: 0.1631 acc_train: 0.9833 loss_val: 0.5730 acc_val: 0.7767 time: 0.0235s\n",
      "Epoch: 0096 loss_train: 0.2187 acc_train: 0.9833 loss_val: 0.5726 acc_val: 0.7800 time: 0.0216s\n",
      "Epoch: 0097 loss_train: 0.1784 acc_train: 0.9833 loss_val: 0.5721 acc_val: 0.7767 time: 0.0203s\n",
      "Epoch: 0098 loss_train: 0.1661 acc_train: 1.0000 loss_val: 0.5722 acc_val: 0.7767 time: 0.0235s\n",
      "Epoch: 0099 loss_train: 0.1596 acc_train: 0.9833 loss_val: 0.5714 acc_val: 0.7800 time: 0.0209s\n",
      "Epoch: 0100 loss_train: 0.1757 acc_train: 1.0000 loss_val: 0.5711 acc_val: 0.7867 time: 0.0210s\n",
      "Epoch: 0101 loss_train: 0.1521 acc_train: 1.0000 loss_val: 0.5711 acc_val: 0.7867 time: 0.0191s\n",
      "Epoch: 0102 loss_train: 0.1595 acc_train: 1.0000 loss_val: 0.5716 acc_val: 0.7800 time: 0.0208s\n",
      "Epoch: 0103 loss_train: 0.1339 acc_train: 0.9833 loss_val: 0.5731 acc_val: 0.7800 time: 0.0213s\n",
      "Epoch: 0104 loss_train: 0.1937 acc_train: 0.9833 loss_val: 0.5757 acc_val: 0.7800 time: 0.0210s\n",
      "Epoch: 0105 loss_train: 0.1450 acc_train: 1.0000 loss_val: 0.5778 acc_val: 0.7767 time: 0.0201s\n",
      "Epoch: 0106 loss_train: 0.1418 acc_train: 0.9833 loss_val: 0.5802 acc_val: 0.7800 time: 0.0192s\n",
      "Epoch: 0107 loss_train: 0.1280 acc_train: 1.0000 loss_val: 0.5819 acc_val: 0.7833 time: 0.0194s\n",
      "Epoch: 0108 loss_train: 0.1447 acc_train: 0.9833 loss_val: 0.5815 acc_val: 0.7800 time: 0.0211s\n",
      "Epoch: 0109 loss_train: 0.1524 acc_train: 0.9833 loss_val: 0.5801 acc_val: 0.7800 time: 0.0210s\n",
      "Epoch: 0110 loss_train: 0.1548 acc_train: 1.0000 loss_val: 0.5782 acc_val: 0.7800 time: 0.0207s\n",
      "Epoch: 0111 loss_train: 0.1495 acc_train: 1.0000 loss_val: 0.5764 acc_val: 0.7733 time: 0.0199s\n",
      "Epoch: 0112 loss_train: 0.1298 acc_train: 1.0000 loss_val: 0.5753 acc_val: 0.7733 time: 0.0204s\n",
      "Epoch: 0113 loss_train: 0.1446 acc_train: 0.9833 loss_val: 0.5746 acc_val: 0.7733 time: 0.0201s\n",
      "Epoch: 0114 loss_train: 0.1457 acc_train: 1.0000 loss_val: 0.5747 acc_val: 0.7767 time: 0.0212s\n",
      "Epoch: 0115 loss_train: 0.1560 acc_train: 1.0000 loss_val: 0.5757 acc_val: 0.7800 time: 0.0206s\n",
      "Epoch: 0116 loss_train: 0.1352 acc_train: 1.0000 loss_val: 0.5762 acc_val: 0.7800 time: 0.0205s\n",
      "Epoch: 0117 loss_train: 0.1519 acc_train: 1.0000 loss_val: 0.5774 acc_val: 0.7767 time: 0.0212s\n",
      "Epoch: 0118 loss_train: 0.1337 acc_train: 1.0000 loss_val: 0.5771 acc_val: 0.7800 time: 0.0212s\n",
      "Epoch: 0119 loss_train: 0.1008 acc_train: 1.0000 loss_val: 0.5768 acc_val: 0.7800 time: 0.0209s\n",
      "Epoch: 0120 loss_train: 0.1119 acc_train: 1.0000 loss_val: 0.5764 acc_val: 0.7800 time: 0.0214s\n",
      "Epoch: 0121 loss_train: 0.1177 acc_train: 1.0000 loss_val: 0.5755 acc_val: 0.7800 time: 0.0194s\n",
      "Epoch: 0122 loss_train: 0.1309 acc_train: 1.0000 loss_val: 0.5745 acc_val: 0.7800 time: 0.0202s\n",
      "Epoch: 0123 loss_train: 0.1325 acc_train: 1.0000 loss_val: 0.5739 acc_val: 0.7833 time: 0.0207s\n",
      "Epoch: 0124 loss_train: 0.1325 acc_train: 1.0000 loss_val: 0.5746 acc_val: 0.7800 time: 0.0238s\n",
      "Epoch: 0125 loss_train: 0.1301 acc_train: 1.0000 loss_val: 0.5763 acc_val: 0.7800 time: 0.0202s\n",
      "Epoch: 0126 loss_train: 0.1353 acc_train: 1.0000 loss_val: 0.5785 acc_val: 0.7833 time: 0.0199s\n",
      "Epoch: 0127 loss_train: 0.1427 acc_train: 0.9833 loss_val: 0.5821 acc_val: 0.7767 time: 0.0211s\n",
      "Epoch: 0128 loss_train: 0.1179 acc_train: 1.0000 loss_val: 0.5849 acc_val: 0.7833 time: 0.0197s\n",
      "Epoch: 0129 loss_train: 0.1133 acc_train: 1.0000 loss_val: 0.5876 acc_val: 0.7867 time: 0.0213s\n",
      "Epoch: 0130 loss_train: 0.1492 acc_train: 1.0000 loss_val: 0.5899 acc_val: 0.7800 time: 0.0200s\n",
      "Epoch: 0131 loss_train: 0.1523 acc_train: 0.9667 loss_val: 0.5893 acc_val: 0.7833 time: 0.0214s\n",
      "Epoch: 0132 loss_train: 0.1137 acc_train: 1.0000 loss_val: 0.5883 acc_val: 0.7833 time: 0.0207s\n",
      "Epoch: 0133 loss_train: 0.1598 acc_train: 0.9833 loss_val: 0.5853 acc_val: 0.7800 time: 0.0195s\n",
      "Epoch: 0134 loss_train: 0.1164 acc_train: 1.0000 loss_val: 0.5840 acc_val: 0.7833 time: 0.0204s\n",
      "Epoch: 0135 loss_train: 0.1183 acc_train: 1.0000 loss_val: 0.5836 acc_val: 0.7867 time: 0.0225s\n",
      "Epoch: 0136 loss_train: 0.1268 acc_train: 0.9833 loss_val: 0.5837 acc_val: 0.7800 time: 0.0192s\n",
      "Epoch: 0137 loss_train: 0.1225 acc_train: 1.0000 loss_val: 0.5842 acc_val: 0.7833 time: 0.0221s\n",
      "Epoch: 0138 loss_train: 0.1213 acc_train: 1.0000 loss_val: 0.5855 acc_val: 0.7767 time: 0.0204s\n",
      "Epoch: 0139 loss_train: 0.1241 acc_train: 0.9833 loss_val: 0.5870 acc_val: 0.7767 time: 0.0202s\n",
      "Epoch: 0140 loss_train: 0.1379 acc_train: 1.0000 loss_val: 0.5886 acc_val: 0.7733 time: 0.0200s\n",
      "Epoch: 0141 loss_train: 0.1241 acc_train: 1.0000 loss_val: 0.5903 acc_val: 0.7733 time: 0.0206s\n",
      "Epoch: 0142 loss_train: 0.1086 acc_train: 1.0000 loss_val: 0.5931 acc_val: 0.7733 time: 0.0258s\n",
      "Epoch: 0143 loss_train: 0.1086 acc_train: 1.0000 loss_val: 0.5959 acc_val: 0.7733 time: 0.0205s\n",
      "Epoch: 0144 loss_train: 0.1414 acc_train: 1.0000 loss_val: 0.5965 acc_val: 0.7700 time: 0.0209s\n",
      "Epoch: 0145 loss_train: 0.1302 acc_train: 0.9833 loss_val: 0.5978 acc_val: 0.7667 time: 0.0200s\n",
      "Epoch: 0146 loss_train: 0.1044 acc_train: 1.0000 loss_val: 0.5973 acc_val: 0.7667 time: 0.0192s\n",
      "Epoch: 0147 loss_train: 0.1247 acc_train: 0.9833 loss_val: 0.5944 acc_val: 0.7700 time: 0.0219s\n",
      "Epoch: 0148 loss_train: 0.1306 acc_train: 0.9667 loss_val: 0.5913 acc_val: 0.7733 time: 0.0222s\n",
      "Epoch: 0149 loss_train: 0.1227 acc_train: 0.9833 loss_val: 0.5883 acc_val: 0.7733 time: 0.0195s\n",
      "Epoch: 0150 loss_train: 0.0974 acc_train: 1.0000 loss_val: 0.5856 acc_val: 0.7733 time: 0.0210s\n",
      "Epoch: 0151 loss_train: 0.1169 acc_train: 1.0000 loss_val: 0.5845 acc_val: 0.7800 time: 0.0230s\n",
      "Epoch: 0152 loss_train: 0.1147 acc_train: 1.0000 loss_val: 0.5837 acc_val: 0.7800 time: 0.0228s\n",
      "Epoch: 0153 loss_train: 0.1254 acc_train: 1.0000 loss_val: 0.5834 acc_val: 0.7800 time: 0.0249s\n",
      "Epoch: 0154 loss_train: 0.1025 acc_train: 1.0000 loss_val: 0.5829 acc_val: 0.7767 time: 0.0210s\n",
      "Epoch: 0155 loss_train: 0.1124 acc_train: 1.0000 loss_val: 0.5825 acc_val: 0.7767 time: 0.0216s\n",
      "Epoch: 0156 loss_train: 0.1056 acc_train: 1.0000 loss_val: 0.5823 acc_val: 0.7767 time: 0.0236s\n",
      "Epoch: 0157 loss_train: 0.1269 acc_train: 0.9833 loss_val: 0.5833 acc_val: 0.7767 time: 0.0219s\n",
      "Epoch: 0158 loss_train: 0.0884 acc_train: 1.0000 loss_val: 0.5840 acc_val: 0.7800 time: 0.0209s\n",
      "Epoch: 0159 loss_train: 0.1015 acc_train: 1.0000 loss_val: 0.5844 acc_val: 0.7800 time: 0.0210s\n",
      "Epoch: 0160 loss_train: 0.1078 acc_train: 1.0000 loss_val: 0.5832 acc_val: 0.7767 time: 0.0208s\n",
      "Epoch: 0161 loss_train: 0.0887 acc_train: 1.0000 loss_val: 0.5829 acc_val: 0.7767 time: 0.0214s\n",
      "Epoch: 0162 loss_train: 0.1253 acc_train: 0.9833 loss_val: 0.5835 acc_val: 0.7733 time: 0.0207s\n",
      "Epoch: 0163 loss_train: 0.1110 acc_train: 1.0000 loss_val: 0.5835 acc_val: 0.7667 time: 0.0215s\n",
      "Epoch: 0164 loss_train: 0.1147 acc_train: 0.9833 loss_val: 0.5864 acc_val: 0.7700 time: 0.0203s\n",
      "Epoch: 0165 loss_train: 0.0925 acc_train: 1.0000 loss_val: 0.5904 acc_val: 0.7700 time: 0.0198s\n",
      "Epoch: 0166 loss_train: 0.1209 acc_train: 0.9833 loss_val: 0.5944 acc_val: 0.7733 time: 0.0200s\n",
      "Epoch: 0167 loss_train: 0.1005 acc_train: 1.0000 loss_val: 0.5966 acc_val: 0.7767 time: 0.0208s\n",
      "Epoch: 0168 loss_train: 0.0962 acc_train: 1.0000 loss_val: 0.5960 acc_val: 0.7733 time: 0.0211s\n",
      "Epoch: 0169 loss_train: 0.1036 acc_train: 1.0000 loss_val: 0.5929 acc_val: 0.7700 time: 0.0206s\n",
      "Epoch: 0170 loss_train: 0.0993 acc_train: 1.0000 loss_val: 0.5888 acc_val: 0.7733 time: 0.0201s\n",
      "Epoch: 0171 loss_train: 0.0904 acc_train: 1.0000 loss_val: 0.5862 acc_val: 0.7700 time: 0.0202s\n",
      "Epoch: 0172 loss_train: 0.1120 acc_train: 0.9833 loss_val: 0.5854 acc_val: 0.7733 time: 0.0205s\n",
      "Epoch: 0173 loss_train: 0.1025 acc_train: 1.0000 loss_val: 0.5845 acc_val: 0.7700 time: 0.0197s\n",
      "Epoch: 0174 loss_train: 0.0986 acc_train: 1.0000 loss_val: 0.5837 acc_val: 0.7767 time: 0.0198s\n",
      "Epoch: 0175 loss_train: 0.1033 acc_train: 0.9833 loss_val: 0.5854 acc_val: 0.7767 time: 0.0195s\n",
      "Epoch: 0176 loss_train: 0.1011 acc_train: 1.0000 loss_val: 0.5890 acc_val: 0.7767 time: 0.0206s\n",
      "Epoch: 0177 loss_train: 0.0989 acc_train: 1.0000 loss_val: 0.5933 acc_val: 0.7733 time: 0.0223s\n",
      "Epoch: 0178 loss_train: 0.0813 acc_train: 1.0000 loss_val: 0.5977 acc_val: 0.7767 time: 0.0198s\n",
      "Epoch: 0179 loss_train: 0.0819 acc_train: 1.0000 loss_val: 0.6010 acc_val: 0.7767 time: 0.0195s\n",
      "Epoch: 0180 loss_train: 0.1066 acc_train: 1.0000 loss_val: 0.6017 acc_val: 0.7767 time: 0.0191s\n",
      "Epoch: 0181 loss_train: 0.0941 acc_train: 1.0000 loss_val: 0.6006 acc_val: 0.7800 time: 0.0198s\n",
      "Epoch: 0182 loss_train: 0.1181 acc_train: 1.0000 loss_val: 0.6006 acc_val: 0.7867 time: 0.0203s\n",
      "Epoch: 0183 loss_train: 0.0794 acc_train: 1.0000 loss_val: 0.6009 acc_val: 0.7800 time: 0.0202s\n",
      "Epoch: 0184 loss_train: 0.1082 acc_train: 0.9833 loss_val: 0.6024 acc_val: 0.7833 time: 0.0199s\n",
      "Epoch: 0185 loss_train: 0.1057 acc_train: 1.0000 loss_val: 0.6026 acc_val: 0.7833 time: 0.0196s\n",
      "Epoch: 0186 loss_train: 0.0926 acc_train: 1.0000 loss_val: 0.6007 acc_val: 0.7767 time: 0.0204s\n",
      "Epoch: 0187 loss_train: 0.0906 acc_train: 1.0000 loss_val: 0.5997 acc_val: 0.7767 time: 0.0302s\n",
      "Epoch: 0188 loss_train: 0.1065 acc_train: 1.0000 loss_val: 0.6002 acc_val: 0.7733 time: 0.0192s\n",
      "Epoch: 0189 loss_train: 0.0793 acc_train: 1.0000 loss_val: 0.6006 acc_val: 0.7733 time: 0.0211s\n",
      "Epoch: 0190 loss_train: 0.0959 acc_train: 1.0000 loss_val: 0.6026 acc_val: 0.7733 time: 0.0199s\n",
      "Epoch: 0191 loss_train: 0.1179 acc_train: 1.0000 loss_val: 0.6035 acc_val: 0.7733 time: 0.0220s\n",
      "Epoch: 0192 loss_train: 0.1150 acc_train: 1.0000 loss_val: 0.6050 acc_val: 0.7733 time: 0.0199s\n",
      "Epoch: 0193 loss_train: 0.0858 acc_train: 1.0000 loss_val: 0.6064 acc_val: 0.7733 time: 0.0200s\n",
      "Epoch: 0194 loss_train: 0.0866 acc_train: 1.0000 loss_val: 0.6074 acc_val: 0.7733 time: 0.0227s\n",
      "Epoch: 0195 loss_train: 0.0984 acc_train: 0.9833 loss_val: 0.6080 acc_val: 0.7733 time: 0.0210s\n",
      "Epoch: 0196 loss_train: 0.0871 acc_train: 0.9833 loss_val: 0.6074 acc_val: 0.7733 time: 0.0213s\n",
      "Epoch: 0197 loss_train: 0.1178 acc_train: 1.0000 loss_val: 0.6060 acc_val: 0.7867 time: 0.0196s\n",
      "Epoch: 0198 loss_train: 0.0775 acc_train: 1.0000 loss_val: 0.6050 acc_val: 0.7867 time: 0.0199s\n",
      "Epoch: 0199 loss_train: 0.0997 acc_train: 1.0000 loss_val: 0.6045 acc_val: 0.7767 time: 0.0208s\n",
      "Epoch: 0200 loss_train: 0.0824 acc_train: 1.0000 loss_val: 0.6024 acc_val: 0.7767 time: 0.0191s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 4.2724s\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "import time\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(features, adj) # The GCN model expects features and adjacency matrix\n",
    "    \n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train]) # Using accuracy from utils\n",
    "    \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate validation set performance\n",
    "    model.eval()\n",
    "    output_val = model(features, adj)\n",
    "    loss_val = F.nll_loss(output_val[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output_val[idx_val], labels[idx_val])\n",
    "\n",
    "    print(f'Epoch: {epoch+1:04d}',\n",
    "          f'loss_train: {loss_train.item():.4f}',\n",
    "          f'acc_train: {acc_train.item():.4f}',\n",
    "          f'loss_val: {loss_val.item():.4f}',\n",
    "          f'acc_val: {acc_val.item():.4f}',\n",
    "          f'time: {time.time() - t:.4f}s')\n",
    "    return loss_val.item()\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "t_total = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    train_epoch(epoch)\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(f\"Total time elapsed: {time.time() - t_total:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbde81cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set...\n",
      "\n",
      "Test set results: loss= 0.5498 accuracy= 0.7780\n"
     ]
    }
   ],
   "source": [
    "# filepath: _Pubmed/main.ipynb\n",
    "# In a new cell\n",
    "\n",
    "# --- 4. Testing ---\n",
    "def test_model():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"\\nTest set results:\",\n",
    "          f\"loss= {loss_test.item():.4f}\",\n",
    "          f\"accuracy= {acc_test.item():.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87216551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "189G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
